{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.core.display import HTML\nHTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\n\n## upload on google workbench!!\n## upload on github!!!","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:37.493414Z","iopub.execute_input":"2023-07-10T15:52:37.493761Z","iopub.status.idle":"2023-07-10T15:52:37.527267Z","shell.execute_reply.started":"2023-07-10T15:52:37.493734Z","shell.execute_reply":"2023-07-10T15:52:37.526119Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<script>Jupyter.notebook.kernel.restart()</script>"},"metadata":{}}]},{"cell_type":"code","source":"## Installing Dependencies\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nimport tensorflow_io as tfio\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten\nfrom itertools import groupby\n\nprint(tf.__version__)\nprint(tfio.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:37.529091Z","iopub.execute_input":"2023-07-10T15:52:37.529476Z","iopub.status.idle":"2023-07-10T15:52:47.851551Z","shell.execute_reply.started":"2023-07-10T15:52:37.529445Z","shell.execute_reply":"2023-07-10T15:52:47.850249Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"2.12.0\n0.31.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **STEP 1: Setup DataLoading function:**","metadata":{}},{"cell_type":"code","source":"def loadAudio(filename): \n    \"\"\"\n    Converts filename into 16k hz mono audio (no stereo audio, easier to process)\n    \"\"\"\n    ## Extracting File from Folders\n    file = tf.io.read_file(filename)\n    \n    ## Extracting Audio component, sampling rate for 16k hz conversion\n    wave, sampleRate = tf.audio.decode_wav(file, desired_channels=1)\n    \n    ## Data Processing, removing extra axis in wave data\n    wave = tf.squeeze(wave, axis=-1)\n    \n    ## integerizing sample rate, easier to process later\n    sampleRate = tf.cast(sampleRate, dtype=tf.int64)\n    \n    ## Standardizing wave\n    wave = tfio.audio.resample(wave, rate_in=sampleRate, rate_out=16000)\n    \n    return wave\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:47.853262Z","iopub.execute_input":"2023-07-10T15:52:47.854581Z","iopub.status.idle":"2023-07-10T15:52:47.862185Z","shell.execute_reply.started":"2023-07-10T15:52:47.854530Z","shell.execute_reply":"2023-07-10T15:52:47.860675Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def load_wav_16k_mono(filename):\n    file_contents=tf.io.read_file(filename)\n    wav,sample_rate=tf.audio.decode_wav(file_contents,desired_channels=1)\n    wav=tf.squeeze(wav,axis=-1)\n    sample_rate=tf.cast(sample_rate,dtype=tf.int64)\n    wav=tfio.audio.resample(wav,rate_in=sample_rate,rate_out=16000)\n    return wav","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:47.865579Z","iopub.execute_input":"2023-07-10T15:52:47.867180Z","iopub.status.idle":"2023-07-10T15:52:47.878967Z","shell.execute_reply.started":"2023-07-10T15:52:47.867117Z","shell.execute_reply":"2023-07-10T15:52:47.877533Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Wave Plots","metadata":{}},{"cell_type":"code","source":"\nCAPUCHIN_FILE = os.path.join('/kaggle/input','z-by-hp-unlocked-challenge-3-signal-processing','Parsed_Capuchinbird_Clips','XC114131-0.wav')\nNOT_CAPUCHIN_FILE= os.path.join('/kaggle/input','z-by-hp-unlocked-challenge-3-signal-processing','Parsed_Not_Capuchinbird_Clips','Crickets-chirping-9.wav')\n\nieBird = load_wav_16k_mono(CAPUCHIN_FILE)\nieNotBird = load_wav_16k_mono(NOT_CAPUCHIN_FILE)\nplt.plot(ieBird)\nplt.plot(ieNotBird)\nplot.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:47.880545Z","iopub.execute_input":"2023-07-10T15:52:47.881088Z","iopub.status.idle":"2023-07-10T15:52:49.219598Z","shell.execute_reply.started":"2023-07-10T15:52:47.881020Z","shell.execute_reply":"2023-07-10T15:52:49.216051Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m CAPUCHIN_FILE \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz-by-hp-unlocked-challenge-3-signal-processing\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParsed_Capuchinbird_Clips\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXC114131-0.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m NOT_CAPUCHIN_FILE\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz-by-hp-unlocked-challenge-3-signal-processing\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParsed_Not_Capuchinbird_Clips\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrickets-chirping-9.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m ieBird \u001b[38;5;241m=\u001b[39m \u001b[43mload_wav_16k_mono\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCAPUCHIN_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m ieNotBird \u001b[38;5;241m=\u001b[39m load_wav_16k_mono(NOT_CAPUCHIN_FILE)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(ieBird)\n","Cell \u001b[0;32mIn[4], line 6\u001b[0m, in \u001b[0;36mload_wav_16k_mono\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      4\u001b[0m wav\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39msqueeze(wav,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m sample_rate\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcast(sample_rate,dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m----> 6\u001b[0m wav\u001b[38;5;241m=\u001b[39m\u001b[43mtfio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrate_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrate_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wav\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/audio_ops.py:462\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(input, rate_in, rate_out, name)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(i):\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_ops\u001b[38;5;241m.\u001b[39mio_audio_resample(\n\u001b[1;32m    459\u001b[0m         i, rate_in\u001b[38;5;241m=\u001b[39mrate_in, rate_out\u001b[38;5;241m=\u001b[39mrate_out, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    460\u001b[0m     )\n\u001b[0;32m--> 462\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorized_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mg1\u001b[39m():\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msqueeze(value, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:565\u001b[0m, in \u001b[0;36mvectorized_map\u001b[0;34m(fn, elems, fallback_to_while_loop, warn)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m   batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(static_first_dims)\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfallback_to_while_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfallback_to_while_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:214\u001b[0m, in \u001b[0;36mpfor\u001b[0;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations, warn)\u001b[0m\n\u001b[1;32m    211\u001b[0m     def_function\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    212\u001b[0m   f \u001b[38;5;241m=\u001b[39m def_function\u001b[38;5;241m.\u001b[39mfunction(f)\n\u001b[0;32m--> 214\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m functions_run_eagerly \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m   def_function\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(functions_run_eagerly)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_fileo_ykg1bu.py:17\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__f\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_pfor_impl), (ag__\u001b[38;5;241m.\u001b[39mld(loop_fn), ag__\u001b[38;5;241m.\u001b[39mld(iters)), \u001b[38;5;28mdict\u001b[39m(fallback_to_while_loop\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(fallback_to_while_loop), parallel_iterations\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(parallel_iterations), warn\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(warn)), fscope)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/audio_ops.py:458\u001b[0m, in \u001b[0;36mresample.<locals>.f\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(i):\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio_audio_resample\u001b[49m(\n\u001b[1;32m    459\u001b[0m         i, rate_in\u001b[38;5;241m=\u001b[39mrate_in, rate_out\u001b[38;5;241m=\u001b[39mrate_out, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    460\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:88\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, attrb)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attrb):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, attrb)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:84\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod \u001b[38;5;241m=\u001b[39m \u001b[43m_load_library\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_library\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:69\u001b[0m, in \u001b[0;36m_load_library\u001b[0;34m(filename, lib)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mNotFoundError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     68\u001b[0m         errs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munable to open file: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, from paths: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilenames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mcaused by: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m )\n","\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n    caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n"],"ename":"NotImplementedError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n    caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","output_type":"error"}]},{"cell_type":"markdown","source":"# **Creating TensorFlow Dataset using our DataLoader Function:**","metadata":{}},{"cell_type":"code","source":"## Creating Binary Output Data\nPOS = '/kaggle/input/z-by-hp-unlocked-challenge-3-signal-processing/Parsed_Capuchinbird_Clips'\nNEG = '/kaggle/input/z-by-hp-unlocked-challenge-3-signal-processing/Parsed_Not_Capuchinbird_Clips'","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.220572Z","iopub.status.idle":"2023-07-10T15:52:49.221047Z","shell.execute_reply.started":"2023-07-10T15:52:49.220825Z","shell.execute_reply":"2023-07-10T15:52:49.220847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## File paths containing all clips known to hold/not hold bird calls\npos = tf.data.Dataset.list_files(POS+'/*.wav') ## Regular Expression for all files in folder\nneg = tf.data.Dataset.list_files(NEG+'/*.wav')\n","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.222702Z","iopub.status.idle":"2023-07-10T15:52:49.223186Z","shell.execute_reply.started":"2023-07-10T15:52:49.222930Z","shell.execute_reply":"2023-07-10T15:52:49.222970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Combining previous bernoulli data\npositives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\nnegatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\nfullData = positives.concatenate(negatives) ## One big tensor of all label data\n\n## We use fulldata as training data for CNN computer vision model\n\n## the 1's or 0's represent the binary output of Yi, where i is the ith image, \n##    Yi is the truth value of the ith image","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.224940Z","iopub.status.idle":"2023-07-10T15:52:49.225430Z","shell.execute_reply.started":"2023-07-10T15:52:49.225201Z","shell.execute_reply":"2023-07-10T15:52:49.225222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EDA - Calculating Average length of a Capuchin Bird**\n- Important, knowing average length => we are capturing the majority of our bird call when slicing through audio files","metadata":{}},{"cell_type":"code","source":"## Calculate Wave Cycle Lengths\nlengths=[]\nfor file in os.listdir(os.path.join('data', 'Parsed_Capuchinbird_Clips')):\n    \n    ## 1d tensor (list) of amplitudes -> length of bird call from training data\n    tensorWave=loadAudio(os.path.join('data', 'Parsed_Capuchinbird_Clips', file)) \n    lengths.append(len(tensorWave))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.227758Z","iopub.status.idle":"2023-07-10T15:52:49.229130Z","shell.execute_reply.started":"2023-07-10T15:52:49.228838Z","shell.execute_reply":"2023-07-10T15:52:49.228866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lengths)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.230622Z","iopub.status.idle":"2023-07-10T15:52:49.231126Z","shell.execute_reply.started":"2023-07-10T15:52:49.230880Z","shell.execute_reply":"2023-07-10T15:52:49.230903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"birdCallMean = tf.math.reduce_mean(lengths)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.232500Z","iopub.status.idle":"2023-07-10T15:52:49.234245Z","shell.execute_reply.started":"2023-07-10T15:52:49.233732Z","shell.execute_reply":"2023-07-10T15:52:49.233779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **PreProcessing**","metadata":{}},{"cell_type":"code","source":"def preProcess(filepath, label):\n    wav = loadAudio(filepath)\n    wav = wav[:48000]\n    \n    ## Just incase some clips dont meet this length\n    zeroPad = tf.zeros([48000 - tf.shape(wav)[0]], dtype=tf.float32)\n    wav=tf.concat([zeroPad, wav], 0)\n    \n    ## Converting to spectogram using Fourier Transform\n    spect = tf.signal.stft(wav, frame_length=320, frame_step=32)\n    spect = tf.abs(spect)\n    \n    ## Making sure we are in appropriate datatype\n    ## CNN model will expect a channels dimension, current tensor does not have that\n    spect = tf.expand_dims(spect, axis=2) \n    return spect, label ## Returning label allows us to use tf.map()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.235503Z","iopub.status.idle":"2023-07-10T15:52:49.235993Z","shell.execute_reply.started":"2023-07-10T15:52:49.235777Z","shell.execute_reply":"2023-07-10T15:52:49.235799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train - Test Datasets**","metadata":{}},{"cell_type":"code","source":"## Tensorflow Data Pipeline\ndata = data.map(preprocess)\ndata = data.cache() ## What is this?\ndata = data.shuffle(buffer_size=1000)\ndata = data.batch(16) ## what is this? ## each index holds 16 samples\ndata = data.prefetch(8)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.237540Z","iopub.status.idle":"2023-07-10T15:52:49.238415Z","shell.execute_reply.started":"2023-07-10T15:52:49.238195Z","shell.execute_reply":"2023-07-10T15:52:49.238219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = data.take(36)\ntest = data.skip(36).take(15)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.239903Z","iopub.status.idle":"2023-07-10T15:52:49.240347Z","shell.execute_reply.started":"2023-07-10T15:52:49.240155Z","shell.execute_reply":"2023-07-10T15:52:49.240175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Building Deep Leaning Model with TensorFlow**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential ## Simple NN\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten ## LAYERS for our NN","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.241818Z","iopub.status.idle":"2023-07-10T15:52:49.242453Z","shell.execute_reply.started":"2023-07-10T15:52:49.242208Z","shell.execute_reply":"2023-07-10T15:52:49.242237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\n## input depends on size of spectogram defined earlier\n## what is RELU\n## EXPLORE THIS FUTHER PLS\n## WHY THESE LAYERS? WHY NOT ADD MORE, OR LESS??\nmodel.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257, 1)))\nmodel.add(Conv2D(16, (3,3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile('Adam', loss='BinaryCrossEntropy', \n              metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.244218Z","iopub.status.idle":"2023-07-10T15:52:49.244780Z","shell.execute_reply.started":"2023-07-10T15:52:49.244579Z","shell.execute_reply":"2023-07-10T15:52:49.244600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Fitting, Measuring Loss, KPI Plots**","metadata":{}},{"cell_type":"code","source":"histogram = model.fit(train, epochs=4, validation_data=test) ## Explore further also Batch?","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.246232Z","iopub.status.idle":"2023-07-10T15:52:49.246832Z","shell.execute_reply.started":"2023-07-10T15:52:49.246536Z","shell.execute_reply":"2023-07-10T15:52:49.246565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(hist.histor['loss'], 'r')\nplt.plot(hist.histor['val_loss'], 'b')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.250169Z","iopub.status.idle":"2023-07-10T15:52:49.250782Z","shell.execute_reply.started":"2023-07-10T15:52:49.250492Z","shell.execute_reply":"2023-07-10T15:52:49.250522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Precision')\nplt.plot(hist.histor['prec'], 'r')\nplt.plot(hist.histor['val_prec'], 'b')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.253644Z","iopub.status.idle":"2023-07-10T15:52:49.254331Z","shell.execute_reply.started":"2023-07-10T15:52:49.253999Z","shell.execute_reply":"2023-07-10T15:52:49.254027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Recall')\nplt.plot(hist.histor['recall'], 'r')\nplt.plot(hist.histor['val_recall'], 'b')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:52:49.255988Z","iopub.status.idle":"2023-07-10T15:52:49.256607Z","shell.execute_reply.started":"2023-07-10T15:52:49.256314Z","shell.execute_reply":"2023-07-10T15:52:49.256344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Forest Clip Parsing Function**","metadata":{}},{"cell_type":"code","source":"## Long Audio clips are mp3s\ndef loadMp3(fileName):\n    \n    res = tfio.audio.AudioIOTensor(fileName)\n    \n    tensor = res.to_tensor()\n    tensor = tf.math.reduce_sum(tensor, axis=1)/2 ## Single channel now\n    \n    sampleRate = res.rate\n    sampleRate = tf.cast(sampleRate, dtype=tf.int64)\n    \n    wav=tfio.audio.resample(tensor, rate_in=sampleRate, rate_out=16000)\n    return wav","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preProcessMp3(sample, index):\n    sample = sample[0]\n    zeroPad = tf.zeros([48000 - tf.shape(sample)[0]], dtype=tf.float32)\n    wav = tf.concat([zero_padding, sample], 0)\n    specto = tf.signal.stft(wav, frame_length=320, frame_step=32)\n    specto = tf.abs(specto)\n    specto = tf.expand_dims(specto, axis=2)\n    return specto, index","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Converting mp3 audio into predictable slices\naudioSlices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000)\naudioSlices = audioSlices.map(preProcessMp3)\naudioSlices = audioSlices.batch(64)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat = model.predict(audioSlices)\nyhat = [1 if prediction > 0.99 else 0 for prediction in yhat]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **GROUP BY**\n- Multiple consecutive predictions should be grouped into one big prediction","metadata":{}},{"cell_type":"code","source":"from itertools import groupby\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat = [key for key, group in groupby(yhat)]\ncalls = tf.math.reduce_sum(yhat).numpy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Final Predictions**","metadata":{}},{"cell_type":"code","source":"## Pure predictions\n\nresult = {}\nfor filename in os.listdir(os.path.join('data', 'Forest Recordings')):\n    PATH = os.path.join('data', 'Forest Recordings',file)\n    \n    wav = loadMp3(PATH)\n    audioSlices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000)\n    audioSlices = audioSlices.map(preProcessMp3)\n    audioSlices = audioSlices.batch(64)\n    \n    yhat = model.predict(audioSlices)\n    result[filename] = yhat","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Converting into 1/0 classes\n\nclasses = {}\nfor file, logits in result.items():\n    classes[file] = [1 if prediction > 0.99 else 0 for prediction in yhat]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Apply full groupby\n\nfinal = {}\nfor file, finalClass in classes.items():\n    final[file] = tf.math.reduce_sum([key for key, group in groupby(yhat)]).numpy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Final Export**","metadata":{}},{"cell_type":"code","source":"import csv\n\nf = open('results.csv', 'w', newline='')\nwriter = csv.writer(f, delimiter=',')\nwriter.writerow(['recording', 'capuchin_calls'])\nfor key, value in final.items():\n    writer.writerow([key, value])\nf.close()","metadata":{},"execution_count":null,"outputs":[]}]}